<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Angela Rodriguez and Anthea Guo</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-anteaterangels/">Click here!</a>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-wegotthisteam">Our Repo!</a>
	
		<figure>
			<img src="images/nostress.avif" alt="No Stress" style="width:70%"/>
			<figcaption>As midterm season approached we both needed this cat. Hope you also have a chill day! </figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<b>What is ray generation?</b>
		<p>In the start we are given a point on an image sensor. We then have to translate it from the camera space (the image sensor) into the real world. This means a whole log of linear transformations.
		 If you don't want to know the math you can skip this part, but in case you were curious:</p>
			<ul>
				<li>We first converted degrees to radians using the formula \( \text{radians} = \text{degrees} \times \frac{\pi}{180} \).</li>
				<li>We shifted the frame to move the center from the original to the real world. This involved translating (0,0) from the bottom-left corner to the center of the frame.</li>
				<li>
					We can represent the 3D vector as \( \mathbf{v} = (x, y, -1) \), where \( x \) and \( y \) are the coordinates on the image sensor, and \(-1\) is the z-coordinate of the camera sensor.
				</li>
				<li>Lastly we multiply these by the screen dimensions and normalize to get the unit vector.</li>
			</ul>

			<figure>
				<img src="images/cam_space_to_ray_generation.png" alt="Ray generation from sensor detection" style="width:70%"/>
				<figcaption>This image helped us understand this a lot</figcaption>
			</figure>
		<b>How did we create the primitive intersections?</b>
			<p>To understand how we created the pixel level intersections. It is great to first review Monte Carlo Integrations <a href="https://en.wikipedia.org/wiki/Monte_Carlo_integration">here</a>. 
			But in short it integrates samples and averages them to approximate the area under the curve.</p>
			<figure>
				<img src="images/MC.png" alt="Ray generation from sensor detection" style="width:70%"/>
				<figcaption>Monte Carlo Integration from scratchapixel.com</figcaption>
			</figure>
			<p>Monte Carlo is a great way to estimate a area (in our case a pixel's color) given a limited number of sampling allowed to improve runtime of an algorithm. 
			This means that we took a fixed amount of random samples from the image sensor within a pixel and then generated a ray and estimated its illuminance. 
			We then integrated over all samples (it was just summing up all the illuminance to be honest) and divided by the number of samples we had to obtain a rough average over the entire pixel.
			This feels familiar to supersampling except not every pixel is sampled since ray generation and illuminance estimation is much more costly than just retrieving a value of a pixel.
		</p>
			<br>

			<b>How does triangle intersection work?</b>
			<p>The Möller–Trumbore algorithm is a fast and efficient method for detecting ray-triangle intersections in 3D space, commonly used in ray tracing.
			This approach leverages barycentric coordinates and Cramer's rule to solve for the intersection point without explicitly computing the triangle’s normal. 
			First, the algorithm calculates two edge vectors and uses the ray direction to determine whether the ray is parallel to the triangle’s plane. 
			If not, it computes the intersection’s barycentric coordinates (u,v), which confirm whether the point lies inside the triangle. The final step determines the intersection distance t, ensuring it falls within the valid ray range. 
			If an intersection is found, additional data such as the interpolated normal is stored for accurate shading. </p>

		<p>Here are some of the simple renderings from small dae files to show that our primitive ray tracing and intersections work</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="images/CBempty.png" width="400px"/>
				  <figcaption>Empty Cornell Box</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="images/CBspheres.png" width="400px"/>
				  <figcaption>Cornell Box with Spheres</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="images/Cgems.png" width="400px"/>
				  <figcaption>Cornell Box with Gems</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="images/banana.png" width="400px"/>
				  <figcaption>Just a banana</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		<b>How does our BVH construction algorithm work?</b>
		<p>
			Bounding Box Hiearchies are created by recursively splitting the scene up into left and right bounding boxes until each box has less than <i>max_leaf_size</i> number of primitives.
			Then using our newly created box hiearchy, we can backtrace a ray along these boxes and check in a log n number of boxes by determining if it is on the right or the left of our center.
			
			Now comes the question of how did we choose our center?
		</p>

		<b>What heuristic was used?</b> <p>The heuristic was the midpoint of the axis with the longest extent. This would try to make sure that we were choosing an axis that would be able to narrow down the most amount of objects based on the assumption that they are sized evenly.
			It may also be true that everything is on one side of an axis and this would lead to an infinite loop. This is because we would never be able to separate the objects since we would continue to choose all of them each time. 
			In order to prevent this, our backup heuristic was just to take half of the objects on a given axis.
		</p>
		<b>BVH Acceleration on objects:</b>
		<p>BVH Acceleration speeds up the time to render bigger models. Nothing took more than 0.1 seconds to render</p>
		<div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 20px;">
			<figure style="text-align: center; flex: 1 1 calc(20% - 20px); max-width: calc(20% - 20px);">
			<img src="images/dragon.png" alt="dragon" style="width:100%"/>
			<figcaption>Dragon: 0.0672s!</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 calc(20% - 20px); max-width: calc(20% - 20px);">
			<img src="images/blob.png" alt="blob" style="width:100%"/>
			<figcaption>blob: 0.0774s!</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 calc(20% - 20px); max-width: calc(20% - 20px);">
			<img src="images/CBlucy.png" alt="CBlucy" style="width:100%"/>
			<figcaption>Cornell Boxed lucy: 0.0852s!</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 calc(20% - 20px); max-width: calc(20% - 20px);">
			<img src="images/wall-e.png" alt="wall-e" style="width:100%"/>
			<figcaption>wall-eee: 0.0717s!</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 calc(20% - 20px); max-width: calc(20% - 20px);">
			<img src="images/cow.png" alt="cow" style="width:100%"/>
			<figcaption>Cow: 0.0625s!</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 calc(20% - 20px); max-width: calc(20% - 20px);">
			<img src="images/Ccoil.png" alt="CBcoil" style="width:100%"/>
			<figcaption>Cornell Boxed coil: 0.0801s!</figcaption>
			</figure>
		</div>

		<p>All of the above rendering times improved significantly, even this is an understatement. This is because we went from n to log n time for each of the path traces and with significant amounts of triangles this can be very significant improvement.
			 For example with the cow: It went from 38.65s to 0.0625 seconds. This is a 618 fold improvement! Holy cow!</p>

			<div style="display: flex; justify-content: center; gap: 20px;">
				<figure style="text-align: center;">
					<img src="images/cowNoAcel.png" alt="cow without acceleration" style="width:100%; max-width: 400px;"/>
					<figcaption>Cow without acceleration: 38.65s</figcaption>
				</figure>
				<figure style="text-align: center;">
					<img src="images/cowWithAcel.png" alt="cow with acceleration" style="width:100%; max-width: 400px;"/>
					<figcaption>Cow with acceleration: 0.0625s</figcaption>
				</figure>
			</div>
			<figure>
				<img src="https://community.meraki.com/t5/image/serverpage/image-id/4425i6C1C79A148AA8011" alt="BVH visualization" style="width:50%"/>
			</figure>
		
		<h2>Part 3: Direct Illumination</h2>
		<p>Before we get into the nitty gritties of illumination we first have to understand the Bidirectional Reflection Distribution Function/p>
		The Bidirectional Reflectance Distribution Function (BRDF) is a fancy way of describing how light bounces off a surface. 
		Imagine shining a flashlight on a table—some of the light reflects into your eyes, some scatters in other directions. 
		BRDF tells us how much light reflects in different directions depending on where the light comes from and the surface’s properties.
		In my opinion, this equation should just be called snell's reflection law but it wasn't up to me.

		It depends on two things:
		<ul>
			<li>
				Incoming angle: <i>w_0</i>
			</li>
			<li>
				Outgoing angle: <i>w_1</i>
			</li>
		</ul>
		and the equation is given by: 
		<figure>
			<img src="images/brdf.png" alt="BRDF reflection" style="width:70%"/>
			<figcaption>Visualization of BRDF reflection angles</figcaption>
		</figure>
		Swapping the reflected light variable to the left we obtain the function for reflected light which we will use later on.
		<figure>
			<img src="images/lightFunc.png" alt="Light reflection function" style="width:70%"/>
			<figcaption>The reflected light function</figcaption>
		</figure>
		<p>Now that we've know how these functions work, let's move on to our two illumination methods:</p>
		<p>In part 3 we implemented two different types of direct illumination:
		</p>
		<h3>1. Uniform Hemisphere Sampling</h3>
		<p>
			The first approach uses uniform hemisphere sampling to estimate direct lighting. This method works by:
		</p>
		<ul>
			<li>Randomly sampling directions uniformly across the hemisphere above the surface point</li>
			<li>Casting rays in these directions to check if they hit light sources</li>
			<li>Accumulating the contribution of light sources hit by these rays</li>
		</ul>
		<p>
			This method has the advantage of being simple to implement, but it can be inefficient because many sampled directions may not hit any light sources, especially when lights are small or far away.
		</p>

		<h3>2. Direct Sampling from Light Source</h3>
		<p>
			The second approach directly samples the light sources, which is more efficient:
		</p>
		<ul>
			<li>For each light in the scene, generate sample points on the light</li>
			<li>Cast rays from the surface point to these sample points</li>
			<li>Check if the rays are blocked (shadow rays)</li>
			<li>Accumulate the contribution of unblocked light samples</li>
		</ul>
		<p>
			This method is more efficient, especially for scenes with small or distant lights, because it focuses samples where they matter most.

			Below are some light sampling images rendered with different numbers of rays sampled.
		</p>
		<h4>Light Ray Sample Comparison</h4>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td>
						<figure>
							<img src="images/bunny_l1.png" width="400px" alt="Light sampling 1 ray"/>
							<figcaption>Light sampling with 1 Ray</figcaption>
						</figure>
					</td>
					<td>
						<figure>
							<img src="images/bunny_l4.png" width="400px" alt="Light sampling 4 rays"/>
							<figcaption>Light sampling with 4 Rays</figcaption>
						</figure>
					</td>
				</tr>
				<tr>
					<td>
						<figure>
							<img src="images/bunny_l16.png" width="400px" alt="Light sampling 16 rays"/>
							<figcaption>Light sampling with 16 Rays</figcaption>
						</figure>
					</td>
					<td>
						<figure>
							<img src="images/bunny_l64.png" width="400px" alt="Light sampling 64 rays"/>
							<figcaption>Light sampling with 64 Rays</figcaption>
						</figure>
					</td>
				</tr>
			</table>
		<b>Progressive Improvement:</b> As light ray count increases from 1 to 64, shadows become progressively smoother, with most improvement visible between 1-16 samples.

		<div class="comparison-section">
			<h3>Comparing Sampling Methods</h3>
			<div class="image-grid">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td>
							<figure>
								<img src="images/task3bunnylowres.png" width="400px" alt="Uniform Hemisphere Low Res"/>
								<figcaption>Uniform Hemisphere Sampling - Low Resolution</figcaption>
							</figure>
						</td>
						<td>
							<figure>
								<img src="images/task4bunnylowres.png" width="400px" alt="Light Importance Low Res"/>
								<figcaption>Light Importance Sampling - Low Resolution</figcaption>
							</figure>
						</td>
					</tr>
					<tr>
						<td>
							<figure>
								<img src="images/task3bunnyhighres.png" width="400px" alt="Uniform Hemisphere High Res"/>
								<figcaption>Uniform Hemisphere Sampling - High Resolution</figcaption>
							</figure>
						</td>
						<td>
							<figure>
								<img src="images/task4bunnyhighres.png" width="400px" alt="Light Importance High Res"/>
								<figcaption>Light Importance Sampling - High Resolution</figcaption>
							</figure>
						</td>
					</tr>
				</table>
			</div>
			

			<h3>Analysis</h3>
			<p>Comparing the two sampling methods reveals several key differences:
			Firstly the noise levels of uniform hemisphere sampling produces noisier images when given the same sampling rates. This is due to the wasted samples on the non-light directions.
			Secondly, the soft shadows appear grainier with hemisphere sampling but smoother with light sampling. 
			Lastly, with the same number of rays, light sampling appears to render an image much closer to reality and thus we can approximate that light importance sampling achieves cleaner results with fewer samples.
			All in all, light importance sampling proves to be superior for efficient path tracing and should be a prioritized method in ray calculations. 
		</p>
		
		<h2>Part 4: Global Illumination</h2>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/bunny.png" alt="global illuminance 1" style="width:100%"/>
				<figcaption>Global Illumination with Bunny</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/test_global.png" alt="global illuminance 3" style="width:100%"/>
				<figcaption>Global Illumination with Banana</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/spheres_global.png" alt="global illuminance 2" style="width:100%"/>
				<figcaption>Global Illumination with Spheres</figcaption>
			</figure>
		</div>
		<p>
			To implement the indirect lighting function, we needed to split our at_least_one_bounce_radiance function
			into separate difference configurations for when we are accumulating bounces and when we aren't. Additionally,
			for when we are at a max_depth_ray of 0, we needed to output only the light emission within the est_radiance_global_illumination()
			function and otherwise sum the zero_bounce_radiance() with the at_least_one_bounce_radiance().

			For our at_least_one_bounce_radiance() function more specifically, our implementation is as follows:

			<ul>
				<li>We set L_out equal to one_bounce_radiance() for the given ray and intersection in the function so we can get the direct lighting source.</li>
				<li>We want to terminate when our given ray's depth is less than or equal to one and then subsequently return our total light collected.</li>
				<li>From our intersection point, we want to also create a new ray which generates this bouncing effect by taking a sample from the surface BSDF
					using our isect.bdsf->sample_f() function. With the given outward radiance w_out, we get the sampled w_in and pdf of the probability density function
					at w_in. Using this, we can generate our new ray using our hit point at the origin hit_p, the normalized product of w_in and o2w, and the offset
					EPS_F with a decrementing depth by 1 for each recursive step.
				</li>
				<li>Our new ray must then be tested if it intersects our scene. If so, then we can calculate the bsdf, use the costheta angle, and recurse!</li>
			  </ul>
		</p>

		<h3>Our Indirect Lighting Function Implementation w/ isAccumBounces</h3>

		In our implementation of with isAccumBounces, we wanted to ensure that we accumulated each of the lightbounces from the max_ray_depth to 1. In order
		to do so, we only wanted to do this when isAccumBounces was true. Otherwise, we only want to return the bounce when r.depth was equivalent to max_ray_depth
		and ignore every other bounce.

		<h3>Our Indirect Lighting Function Implementation w/ Russian Roulette</h3>
		
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/russian_roulette_slide.png" alt="RR Slide" style="width:100%"/>
				<figcaption>Direct Illuminance</figcaption>
			</figure>
		</div>

		So that our recursion does not occur indefinitely, we integrated the Russian Roulette termination from lecture into our function. We first
		use a probabilistic value through the coin_flip() function in order to decide an unbiased estimate of how much light contribution should be inputted
		within our scenes. By using this feature with max_ray_depth instead of isAccumBounces, we allow for a more realistic visualization of global illumination.

		<h3>Direct vs. Indirect Illumination</h3>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/spheres_global_direct.png" alt="direct illuminance" style="width:100%"/>
				<figcaption>Direct Illuminance</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/spheres_indirect.png" alt="indirect illuminance" style="width:100%"/>
				<figcaption>Indirect Illuminance</figcaption>
			</figure>
		</div>

		<p>For direct illuminance, we notice that there is a stark contrast between each of the surfaces due to the light emission coming from the 
			top lighting source in the ceiling. However, we notice in the indirect illuminance that we can see the illuminance and color bleeding 
			occuring within each surface from the walls. Only seeing these difference do we notice how combining these two illumination values can we
			have a more realistic form of illumination like global illuminance.

			Therefore, the differences are when we are adding each accumulation and one_bounce_radiance() into our L_out.
		</p>


		<h3>Different mth Bounces of Light w/ isAccumBounces = false</h3>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m0_non.png" alt="non-accum 0" style="width:100%"/>
				<figcaption>m = 0</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m1_non.png" alt="non-accum 1" style="width:100%"/>
				<figcaption>m = 1</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m2_non.png" alt="non-accum 2" style="width:100%"/>
				<figcaption>m = 2</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m3_non.png" alt="non-accum 3" style="width:100%"/>
				<figcaption>m = 3</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m4_non.png" alt="non-accum 4" style="width:100%"/>
				<figcaption>m = 4</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m5_non.png" alt="non-accum 5" style="width:100%"/>
				<figcaption>m = 5</figcaption>
			</figure>
		</div>

		<p>From these images we can notice how, in m = 2, it is the first indication of when indirect illuminance
			is prevalent. The light is now bounces across the different walls in order to gain light from the other surfaces
			rather than any additional accumulating light. Furthermore, we notice how color bleeding occurs across the bunny and the other
			floors and walls as a result of this effect.
		</p>
		<p>
			When m = 3, the image starts to become darker as more light attempts to be accumulated from the current sources available.
			Due to no additional accumulated light being carried, however, it becomes more difficult to find radiance, which is why we notice a darker
			scene with shadowed areas.
		</p>

		<p>As the m begins to increase, we can see that the lighting becomes more even along the surface. Therefore, the effect seems to work but with less
			light sources and more shadows existing within the scene. However, the lower m depths have a more distinct effect (m = 0 only has light emission, m = 1 has direct illumination).
		</p>

		<h3>Different mth Bounces of Light w/ isAccumBounces = true</h3>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m0.png" alt="accum 0" style="width:100%"/>
				<figcaption>m = 0</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m1.png" alt="accum 1" style="width:100%"/>
				<figcaption>m = 1</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m2.png" alt="accum 2" style="width:100%"/>
				<figcaption>m = 2</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m3.png" alt="accum 3" style="width:100%"/>
				<figcaption>m = 3</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m4.png" alt="accum 4" style="width:100%"/>
				<figcaption>m = 4</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m5.png" alt="accum 5" style="width:100%"/>
				<figcaption>m = 5</figcaption>
			</figure>
		</div>

		<ul>
			<li>m = 0: no drastic difference due to only measuring light emission.</li>
			<li>m = 1: no drastic difference due to only measuring the direct illuminance of the scene with one_bounce_radiance().</li>
			<li>Within m = 2 to m = 5 due we notice how the accumulated bounces allow for a more illuminated scene with realistic
				lighting effects. When we remove accumulation, we see these lighting effects because the lighting becomes more spread out 
				across the scene despite having less light for the image to be visible. Additionally, as bounces increase, we notice how 
				there is more similarities to lower depths such as m = 4 and m = 5 for both when isAccumBounces is false and true. This shows how large amounts light bounces are not necessary 
				to make a scene's illuminance look realistic.
			</li>
		  </ul>

		<h3>Different mth Bounces of Light w/ Russian Roulette</h3>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m0._roulette.png" alt="accum 0" style="width:100%"/>
				<figcaption>m = 0</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m1_roulette.png" alt="russian 1" style="width:100%"/>
				<figcaption>m = 1</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m2_roulette.png" alt="accum 2" style="width:100%"/>
				<figcaption>m = 2</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m3_roulette.png" alt="accum 3" style="width:100%"/>
				<figcaption>m = 3</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m4_roulette.png" alt="accum 4" style="width:100%"/>
				<figcaption>m = 4</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/CBbunny_m100_roulette.png" alt="accum 5" style="width:100%"/>
				<figcaption>m = 5</figcaption>
			</figure>
		</div>


		<h3>Different Sample per Pixel Rates</h3>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s1_l4.png" alt="wall-e 1 sample" style="width:100%"/>
				<figcaption>1 sample per pixel</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s2_l4.png" alt="wall-e 2 samples" style="width:100%"/>
				<figcaption>2 samples per pixel</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s4_l4.png" alt="wall-e 4 samples" style="width:100%"/>
				<figcaption>4 samples per pixel</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s8_l4.png" alt="wall-e 8 samples" style="width:100%"/>
				<figcaption>8 samples per pixel</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s16_l4.png" alt="wall-e 16 samples" style="width:100%"/>
				<figcaption>16 samples per pixel</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s64_l4.png" alt="wall-e 64 samples" style="width:100%"/>
				<figcaption>64 samples per pixel</figcaption>
			</figure>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/wall-e_s1024_l4.png" alt="wall-e 1024 samples" style="width:100%"/>
				<figcaption>1024 samples per pixel</figcaption>
			</figure>
		</div>

		<p>
			These images represent how the sample per pixel rate affects the quality of the image that is outputted after rendering. With a lower sample per pixel rate,
			the scene becomes more grainy and the shapes become less noticable due to this impact on the render. However, in the 1024 samples per pixel image, the 
			scene becomes more smooth and high-quality in comparison. While the higher samples per pixel cause the render time to be more lengthy, it allows for a quality image
			that more accurately represents the image being rendered. If you want a balance of having a smooth but also less costly render, having samples per pixel in-between these 
			values such as 16 or 64 always for a slightly noisy but realistic image.
		</p>
		<h2>Part 5: Adaptive Sampling</h2>
		<p>In our adaptive sampling implementation, we utilized the technique to adjust the number of samples
			per pixel based on the variance values within our scene's illumination. To do so, we focused on getting
			samples from more noisy areas with higher variance and stop otherwise. This allows for a higher 
			effiency with our scene generation.
		</p>
		<p>
			To do so, we accumulated the illuminance in each iteration of our sample along with the squared illuminance. 
			if we have reached a level in the samplesPerBatch value, we want to then calculate the mean, variance, and standard deviation
			in order to calculate the convergence of the samples. If our I is less than maxTolerance * mean, then we break from our iteration
			since the samples have already converged. We can then track the number of samples we did use in our scene more accurately and output 
			our image. This allows for an increase in efficiency of our render and using less samples and ray accumulation than necessary in the 
			build.
		</p>
		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/bunny.png" alt="global bunny" style="width:100%"/>
				<figcaption>Bunny Scene</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/bunny_rate.png" alt="rate bunny" style="width:100%"/>
				<figcaption>Bunny Scene Light Map</figcaption>
			</figure>
		</div>

		<div style="display: flex; flex-wrap: wrap; justify-content: center;">
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/test_global.png" alt="global banana" style="width:100%"/>
				<figcaption>Banana Scene</figcaption>
			</figure>
			<figure style="text-align: center; flex: 1 1 30%; margin: 10px;">
				<img src="images/test_global_rate.png" alt="rate banana" style="width:100%"/>
				<figcaption>Banana Scene Light Map</figcaption>
			</figure>
		</div>
	
		</div>
	</body>
</html>